# 第3课讲义：统一内存 + 数组求最大值

## 课前回顾 (1分钟)

上节课（0202-vec-add.cu）我们学了：
- 向量加法的基本kernel
- 手动内存管理：`cudaMalloc` → `cudaMemcpy` → kernel → `cudaMemcpy` → `cudaFree`
- 线程索引计算：`tid = blockIdx.x * blockDim.x + threadIdx.x`

**问题**：这个流程繁琐吗？每次都要手动拷贝数据，容易出错！

---

## 今天要解决的问题 (1分钟)

**任务**：给定1000万个随机整数，找出最大值

**挑战**：
1. 如何简化内存管理？（统一内存）
2. 如何将N个数据"合并"成1个结果？（归约算法）
3. GPU真的比CPU快吗？（性能对比）

---

## 核心概念速讲 (3分钟)

### 1. 统一内存 (Unified Memory)

**传统方式** (0202的做法):
```cuda
int *h_a, *d_a;
h_a = (int*)malloc(N * sizeof(int));  // CPU内存
cudaMalloc(&d_a, N * sizeof(int));    // GPU内存
cudaMemcpy(d_a, h_a, ..., H2D);       // 拷贝到GPU
// ... kernel ...
cudaMemcpy(h_a, d_a, ..., D2H);       // 拷贝回CPU
```

**统一内存方式** (今天):
```cuda
int *data;
cudaMallocManaged(&data, N * sizeof(int));  // 一步搞定！
// CPU可以访问：data[i] = 123;
// GPU也能访问：kernel<<<...>>>(data, ...)
// 自动处理数据迁移！
```

**优势**：
- 代码简洁：少写50%代码
- 自动迁移：系统自动在CPU/GPU间移动数据
- 初学友好：专注算法，不被内存管理分心

**注意**：需要 `cudaDeviceSynchronize()` 确保GPU完成后CPU才访问

---

### 2. 归约 (Reduction) 概念

**什么是归约**？
- 将N个输入 → 1个输出
- 例子：求和、求最大/最小值、求平均数

**今天的问题**：[5, 2, 9, 1, 7, ...] → 最大值 = 9

**朴素GPU思路**（今天的实现）：
```
线程0: 检查元素0, 100, 200, ... → local_max = 99
线程1: 检查元素1, 101, 201, ... → local_max = 87
线程2: 检查元素2, 102, 202, ... → local_max = 95
...
最后：用 atomicMax() 找出所有线程的最大值
```

**Grid-Stride Loop 为什么需要？**
- 数据：1000万个
- 线程：假设256 × 1024 = 26万个
- 结论：每个线程要处理 1000万 / 26万 ≈ 38个数据

```cuda
for (int i = tid; i < n; i += stride) {
    // 线程tid处理: tid, tid+stride, tid+2*stride, ...
}
```

---

### 3. 原子操作 (Atomic Operation)

**问题**：多个线程同时更新 `result`，怎么保证不出错？

**错误示例**（会有race condition）：
```cuda
if (local_max > *result) {
    *result = local_max;  // 危险！多线程同时写
}
```

**正确做法**（原子操作）：
```cuda
atomicMax(result, local_max);  // 硬件保证安全
```

**atomicMax原理**：
- 硬件级别的互斥锁
- 保证同一时间只有一个线程能修改
- 自动比较并更新最大值

**代价**：原子操作比普通操作慢（下节课会优化掉）

---

## 代码结构预告 (等会live coding的框架)

```
main() {
    // 1. 统一内存分配
    cudaMallocManaged(&data, ...);

    // 2. 初始化数据
    for (i = 0; i < N; i++) data[i] = rand();

    // 3. CPU版本（验证用）
    cpu_max = findMaxCPU(data, N);

    // 4. GPU版本
    findMaxGPU_naive<<<blocks, threads>>>(data, N, result);
    cudaDeviceSynchronize();

    // 5. 对比结果和性能
    if (cpu_max == *result) printf("正确！");
    printf("加速比: %.2fx\n", cpu_time / gpu_time);

    // 6. 清理
    cudaFree(data);
}
```

---

## 本节课的目标检查

学完这节课，你应该能：
- ✅ 使用 `cudaMallocManaged()` 分配统一内存
- ✅ 理解 grid-stride loop 的作用
- ✅ 知道 `atomicMax()` 的用法和代价
- ✅ 能写出CPU验证代码
- ✅ 能测量和对比CPU vs GPU性能

---

## 接下来：20分钟 Live Coding

我会从头写完整个程序，边写边解释每一行的作用。

**预期效果**：
- 编译通过
- 运行成功
- GPU比CPU快 5-10x（数据量大时）
- 结果正确验证通过

准备好了吗？让我们开始敲代码！🚀
