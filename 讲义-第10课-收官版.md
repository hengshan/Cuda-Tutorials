# 第10课讲义：CUDA Streams 综合实战（收官之作）

## 课前回顾 (2分钟)

### 前9课我们学到了什么？

**优化之路：让单个任务跑得更快**

```
第3课: 找最大值 - 朴素版
       ↓ 原子操作太慢
第4课: 共享内存优化 (3-5x加速)
       ↓ 还有优化空间
第5课: Warp Shuffle (再1.5-2x加速)
       ↓ 总加速60倍！

第6课: 矩阵乘法 - 朴素版
       ↓ 全局内存访问太多
第7课: Tiling技术 (10-20x加速)
       ↓ 共享内存 + 数据复用
```

**今天的问题**：单个kernel已经很快了，还能更快吗？

**答案**：能！但不是优化kernel本身，而是优化**整个系统**！

---

## 今天要解决的核心问题 (3分钟)

### 场景：GPU程序的"等待浪费"

**传统单任务执行**：
```
时间轴：
───────────────────────────────────────────────────────────►
CPU:  [准备数据A]               [处理结果]        [空闲]
                  ↓                    ↑
GPU:          [传输A]  [计算A]  [传回A]    [空闲GPU！]
              └────────串行执行────────┘

问题1：GPU传输数据时，计算单元空闲 ❌
问题2：GPU计算时，PCIe通道空闲 ❌
问题3：CPU等待GPU时，不能准备下一批数据 ❌
```

**理想的执行模型**：
```
时间轴：
─────────────────────────────────────────────────►
Stream 0:  [传A0] [算A0] [回A0]
Stream 1:      [传A1] [算A1] [回A1]
Stream 2:          [传A2] [算A2] [回A2]
Stream 3:              [传A3] [算A3] [回A3]
           └──────重叠！并发！──────┘

优势：
✓ 传输和计算重叠（硬件并发）
✓ 总时间 ≈ max(传输, 计算) 而非 sum(传输, 计算)
✓ GPU和PCIe都充分利用
```

---

## 核心概念速讲 (5分钟)

### 1. CUDA Stream（流）

**定义**：
- 独立的操作队列
- 同一stream内的操作：**按顺序**执行
- 不同stream的操作：**可以并发**执行

**类比：高速公路**
```
┌─────────────────────────────────────────┐
│ 单车道（无stream）                       │
│   车1 → 车2 → 车3 → 车4  (排队！)         │
└─────────────────────────────────────────┘

┌─────────────────────────────────────────┐
│ 多车道（多stream）                        │
│   车道1: 车1 →                            │
│   车道2: 车2 →     (并行！)               │
│   车道3: 车3 →                            │
│   车道4: 车4 →                            │
└─────────────────────────────────────────┘
```

**API**：
```cuda
// 创建stream
cudaStream_t stream;
cudaStreamCreate(&stream);

// 在stream中执行操作
cudaMemcpyAsync(..., stream);        // 异步传输
kernel<<<grid, block, 0, stream>>>(); // 指定stream
cudaMemcpyAsync(..., stream);        // 异步传回

// 销毁stream
cudaStreamDestroy(stream);
```

---

### 2. 异步操作 vs 同步操作

**同步**（默认）：
```cuda
cudaMemcpy(...);  // CPU等待传输完成才继续
```
- CPU阻塞，等待操作完成
- 安全、简单，但慢

**异步**：
```cuda
cudaMemcpyAsync(..., stream);  // CPU立即返回
```
- CPU立即返回，操作在后台执行
- 高效，但需要正确管理依赖

---

### 3. Pinned Memory（页锁定内存）

**为什么需要？**

| 内存类型 | 普通内存 (malloc) | Pinned Memory (cudaMallocHost) |
|---------|------------------|-------------------------------|
| 物理位置 | 可被OS换页到磁盘 | 锁定在RAM |
| GPU直接访问 | ❌ 需要中间缓冲 | ✅ DMA直接访问 |
| 传输带宽 | ~6-12 GB/s | ~12-25 GB/s (2-3x) |
| **异步拷贝** | ❌ **不支持** | ✅ **必需** |

**关键点**：异步传输**必须**用Pinned Memory！

```cuda
// 错误：异步传输用普通内存（不会报错，但不异步！）
float *h_data = (float*)malloc(size);
cudaMemcpyAsync(d_data, h_data, size, ..., stream);  // 实际是同步！

// 正确：异步传输用Pinned Memory
float *h_data;
cudaMallocHost(&h_data, size);  // Pinned Memory
cudaMemcpyAsync(d_data, h_data, size, ..., stream);  // 真正异步
```

---

### 4. 计算与传输重叠的原理

**硬件基础**：
```
┌─────────────────────────────────────────────┐
│              GPU芯片                         │
│  ┌─────────────┐       ┌──────────────┐    │
│  │  DMA引擎    │       │  SM计算单元   │    │
│  │  (传输)     │       │  (计算)       │    │
│  └─────────────┘       └──────────────┘    │
│       ↕                       ↕              │
│   PCIe总线              GPU显存              │
└─────────────────────────────────────────────┘

关键：DMA引擎 和 计算单元 是**独立硬件**！
```

**重叠条件**：
1. 使用不同的stream ✓
2. 操作使用不同硬件资源 ✓
3. 数据无依赖关系 ✓

**时间线对比**：

```
单Stream（串行）：
───────────────────────────────────────────────────►
  [H2D_0][Kernel_0][D2H_0][H2D_1][Kernel_1][D2H_1]
  └────────────── 总时间 = 6单位 ──────────────┘

多Stream（并发）：
───────────────────────────────────────────────────►
  [H2D_0][Kernel_0][D2H_0]
     [H2D_1][Kernel_1][D2H_1]
        [H2D_2][Kernel_2][D2H_2]
  └───── 总时间 = 3-4单位 ─────┘

加速比 = 6 / 3.5 ≈ 1.7x
```

---

## 本课程的独特价值 (1分钟)

### 从"单点优化"到"系统思维"

**前9课：微观优化**
- 目标：让单个kernel跑得更快
- 方法：算法、内存、warp
- 思维：代码级优化

**第10课：宏观优化**
- 目标：让整个应用更高效
- 方法：并发、流水线、隐藏延迟
- 思维：系统级优化

**类比**：
- 前9课 = 优化单个工人的效率（用更好的工具）
- 第10课 = 优化整个工厂的产能（流水线作业）

---

## 今天的代码结构 (2分钟)

### Part A: 矩阵乘法 + Streams

**展示内容**：
```
1. 同步执行 - Naive版本
   → 回顾第6课：全局内存访问慢

2. 同步执行 - Tiled版本
   → 回顾第7课：共享内存优化

3. 异步执行 - Tiled + 4 Streams
   → 第10课新知识：分块并发

   优化原理：
   - 将2048×2048矩阵分成4块（每块512行）
   - 每块用一个stream处理
   - Stream 0传输时，Stream 1计算
```

**关键代码**：
```cuda
// 创建4个streams
cudaStream_t streams[4];
for (int i = 0; i < 4; i++) {
    cudaStreamCreate(&streams[i]);
}

// 每个stream处理一块数据
for (int i = 0; i < 4; i++) {
    int offset = i * chunkSize;

    // 异步H2D（A的一块）
    cudaMemcpyAsync(d_A + offset, h_A + offset,
                    chunkSize, ..., streams[i]);

    // 异步kernel
    matmulGPU_tiled<<<grid, block, 0, streams[i]>>>(
        d_A + offset, d_B, d_C + offset, ...);

    // 异步D2H
    cudaMemcpyAsync(h_C + offset, d_C + offset,
                    chunkSize, ..., streams[i]);
}

cudaDeviceSynchronize();  // 等待所有完成
```

---

### Part B: 规约 + Streams

**展示内容**：
```
1. 同步执行 - Naive/Shared/Warp
   → 回顾第3-5课的优化路径

2. 异步执行 - Warp + 4 Streams
   → 并发规约多个数据块

   优化原理：
   - 1000万元素分成4块（每块250万）
   - 每块独立求最大值
   - atomicMax合并结果
```

---

## 性能分析实战 (2分钟)

### NVTX标记：可视化性能瓶颈

**代码中的NVTX标记**（已添加）：
```cuda
// H2D传输（蓝色）
nvtxRangePushColor("H2D Transfer", NVTX_COLOR_MEMCPY_H2D);
cudaMemcpy(...);
nvtxRangePop();

// Kernel执行（红色/黄色）
nvtxRangePushColor("Matmul Kernel", NVTX_COLOR_KERNEL);
kernel<<<...>>>();
nvtxRangePop();

// D2H传输（绿色）
nvtxRangePushColor("D2H Transfer", NVTX_COLOR_MEMCPY_D2H);
cudaMemcpy(...);
nvtxRangePop();
```

**分析流程**：
```bash
# 1. 编译（必须链接nvToolsExt）
nvcc -arch=sm_120 -o lesson10 1002-streams-async.cu -lnvToolsExt

# 2. Profiling
nsys profile -o report ./lesson10

# 3. 查看时间线
nsys-ui report.nsys-rep
```

**在Nsight Systems中查看**：
- 同步版本：蓝色(H2D) → 红色(Kernel) → 绿色(D2H) **串行排列**
- 异步版本：多条stream **并行重叠**

---

### NCU分析：深度Kernel性能

```bash
# 分析所有kernel
ncu --set full -o ncu_report ./lesson10

# 查看报告
ncu-ui ncu_report.ncu-rep
```

**重点指标**：
| 指标 | Naive | Tiled | Warp Shuffle |
|------|-------|-------|--------------|
| Memory Throughput | 低 | 高 | 高 |
| Warp Efficiency | 中 | 高 | 高 |
| L1 Cache Hit Rate | 低 | 高 | 高 |
| Occupancy | 高 | 中 | 高 |

---

## Live Coding 重点 (20分钟)

### 演示流程建议

**1. 编译运行 (3分钟)**
```bash
# 编译
cd Tutorials
nvcc -arch=sm_120 -o lesson10 1002-streams-async.cu -lnvToolsExt

# 运行
./lesson10

# 观察输出：
# - Part A: 矩阵乘法性能对比
# - Part B: 规约性能对比
```

**2. 重点讲解：矩阵乘法 (8分钟)**
- 同步执行：强调串行等待
- 异步执行：展示分块策略
- 性能对比：1.5-2x加速（取决于数据大小）

**3. 重点讲解：规约 (4分钟)**
- 回顾优化路径：naive → shared → warp
- Stream版本：并发规约

**4. Nsight Systems分析 (5分钟)**
```bash
nsys profile -o report ./lesson10
nsys-ui report.nsys-rep
```

**展示要点**：
- 打开Timeline视图
- 放大查看：
  - 同步版本：操作串行
  - 异步版本：Stream重叠
- 指出：GPU Utilization提升

---

## 常见陷阱和最佳实践 (2分钟)

### 陷阱1：Default Stream的隐式同步

```cuda
// 错误：混用default stream和非default stream
kernel1<<<grid, block>>>();           // Default stream (NULL)
kernel2<<<grid, block, 0, stream1>>>(); // 非default stream
// 问题：kernel2会等待kernel1完成！
```

**解决**：总是显式指定stream

---

### 陷阱2：数据依赖破坏并发

```cuda
// 错误：Stream 1依赖Stream 0的数据
cudaMemcpyAsync(d_a, h_a, size, ..., stream0);
kernel<<<..., stream1>>>(d_a, ...);  // 读取d_a，必须等stream0
```

**解决**：确保每个stream处理独立数据

---

### 陷阱3：Pinned Memory过度使用

```cuda
// 危险：分配过多Pinned Memory
cudaMallocHost(&h_data, 50GB);  // 可能导致系统内存不足！
```

**解决**：控制在物理内存的10-20%以内

---

### 最佳实践

**1. Stream数量选择**
- 太少（1-2个）：并发不足
- 太多（>8个）：调度开销大
- **推荐**：2-4个（根据硬件）

**2. 数据分块策略**
- 每块足够大：避免launch开销
- 每块足够小：实现流水线
- **经验**：每块处理时间 ≈ 5-10ms

**3. 内存使用**
- 优先用Pinned Memory（异步必需）
- 考虑内存池（避免频繁分配）
- 监控使用量

---

## 课程总结 (3分钟)

### 完整的CUDA性能优化框架

```
┌───────────────────────────────────────────────────────────┐
│                 CUDA性能优化金字塔                         │
├───────────────────────────────────────────────────────────┤
│  Level 4: 系统级优化 (第10课)                             │
│  • Streams（计算传输重叠）                                 │
│  • Multi-GPU（跨卡并行）                                  │
│  • CUDA Graphs（减少launch开销）                          │
│  → 目标：整体吞吐量最大化                                  │
├───────────────────────────────────────────────────────────┤
│  Level 3: 架构级优化 (第8-9课)                            │
│  • Cooperative Groups（灵活同步）                         │
│  • Thread Block Clusters（分布式共享内存）                │
│  → 目标：利用新硬件特性                                    │
├───────────────────────────────────────────────────────────┤
│  Level 2: 算法级优化 (第3-7课)                            │
│  • Tiling（数据复用）                                     │
│  • Reduction（树形归约）                                  │
│  • Warp Shuffle（warp级通信）                             │
│  → 目标：减少内存访问、提高并行度                          │
├───────────────────────────────────────────────────────────┤
│  Level 1: 基础实现 (第1-2课)                              │
│  • 正确的并行算法                                          │
│  • 合理的线程配置                                          │
│  → 目标：功能正确、基本并行                                │
└───────────────────────────────────────────────────────────┘
```

---

### 关键收获

**技术层面**：
- ✅ 理解Stream的工作原理
- ✅ 掌握异步执行模型
- ✅ 学会使用NVTX和NCU分析性能
- ✅ 完整体验从naive到优化的全过程

**思维层面**：
- 🧠 单点优化 vs 系统优化
- 🧠 延迟 vs 吞吐量
- 🧠 理论性能 vs 实际性能
- 🧠 何时优化，何时够用

---

### 实战建议

**1. 分析瓶颈（70%时间）**
- 用Profiler找真正的瓶颈
- 不要盲目优化
- 测量，不要猜测

**2. 选择优化方向（20%时间）**
- 内存瓶颈 → Tiling
- 计算瓶颈 → 算法优化
- 传输瓶颈 → Streams

**3. 实施优化（10%时间）**
- 小步迭代
- 每次优化后验证正确性
- 记录性能数据

---

### 下一步学习路径

**立即实践**：
1. 运行本课程代码
2. 用nsys分析时间线
3. 修改stream数量，观察效果

**进阶主题**：
1. **CUDA Graphs**：捕获操作序列，减少launch开销
2. **cuBLAS/cuDNN**：工业级优化库（比手写快）
3. **Tensor Cores**：AI专用硬件（FP16混合精度）
4. **Multi-GPU**：NCCL库实现跨卡通信

**项目实战**：
- 深度学习算子优化（卷积、矩阵乘）
- 科学计算应用（流体模拟、分子动力学）
- 图像处理（滤波、变换）

---

## 最后的话 (1分钟)

### 性能优化的哲学

> "过早优化是万恶之源" - Donald Knuth

**正确的优化流程**：
```
1. 先让程序正确运行
2. 分析找出真正的瓶颈
3. 优化瓶颈（从性价比高的开始）
4. 验证正确性和性能
5. 重复2-4直到满足需求
```

**何时停止优化**：
- ✓ 性能满足需求
- ✓ 进一步优化收益递减
- ✓ 代码复杂度过高影响维护

---

### 恭喜你完成CUDA核心课程！

**你现在掌握的技能**：
- ✅ CUDA编程基础
- ✅ 内存层次和优化
- ✅ 并行算法设计
- ✅ 性能分析和调优
- ✅ 系统级优化思维

**你已经具备**：
- 独立开发CUDA应用的能力
- 阅读和优化现有CUDA代码的能力
- 持续学习新特性的基础

---

## 课后作业

### 必做（巩固理解）

1. **实验1：Profiling分析**
   - 运行lesson10程序
   - 用nsys profile生成报告
   - 截图对比同步vs异步的时间线
   - 分析：哪里重叠了？GPU利用率如何？

2. **实验2：参数调优**
   - 修改stream数量（1, 2, 4, 8）
   - 记录每种配置的性能
   - 找出最优配置
   - 解释原因

3. **思考题**
   - 为什么矩阵乘法用stream效果好，但规约效果有限？
   - 提示：考虑计算时间 vs 传输时间的比例

### 选做（深入探索）

4. **高级实验：混合并发**
   - 同时运行矩阵乘法和规约
   - 使用不同的stream
   - 验证是否真正并发（用nsys）

5. **NCU深度分析**
   - 用ncu分析matmul_naive vs matmul_tiled
   - 对比Memory Throughput、Warp Efficiency
   - 写一份分析报告（500字）

6. **代码优化**
   - 当前代码中B矩阵每个stream都传输
   - 优化：只传输一次，所有stream共享
   - 测量性能提升

---

## 附录：快速参考

### CUDA Streams API

```cuda
// 创建和销毁
cudaStreamCreate(&stream);
cudaStreamDestroy(stream);

// 异步操作
cudaMemcpyAsync(..., stream);
kernel<<<grid, block, 0, stream>>>();

// 同步
cudaStreamSynchronize(stream);  // 等待指定stream
cudaDeviceSynchronize();        // 等待所有stream

// 查询
cudaStreamQuery(stream);  // 非阻塞查询stream状态
```

---

### Pinned Memory API

```cuda
// 分配和释放
cudaMallocHost(&ptr, size);
cudaFreeHost(ptr);

// 高级选项
cudaHostAlloc(&ptr, size, cudaHostAllocDefault);
cudaHostAlloc(&ptr, size, cudaHostAllocPortable);     // 多GPU
cudaHostAlloc(&ptr, size, cudaHostAllocWriteCombined); // 优化写
```

---

### NVTX API

```cuda
#include <nvToolsExt.h>

// 简单标记
nvtxRangePush("Name");
// 代码...
nvtxRangePop();

// 带颜色标记
nvtxEventAttributes_t attr = {0};
attr.version = NVTX_VERSION;
attr.colorType = NVTX_COLOR_ARGB;
attr.color = 0xFF00FF00;  // ARGB格式
attr.messageType = NVTX_MESSAGE_TYPE_ASCII;
attr.message.ascii = "Name";
nvtxRangePushEx(&attr);
// 代码...
nvtxRangePop();
```

---

### Profiling命令

```bash
# Nsight Systems（时间线分析）
nsys profile -o report ./app
nsys-ui report.nsys-rep

# Nsight Compute（kernel分析）
ncu --set full -o report ./app
ncu-ui report.ncu-rep

# 只分析特定kernel
ncu --kernel-name matmulGPU_tiled ./app
```

---

**讲义结束**

*CUDA 13.1教程 | RTX 5090 Blackwell | 第10课收官版 | 2025*
