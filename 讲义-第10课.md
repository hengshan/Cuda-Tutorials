# 第10课讲义：CUDA Streams 与异步操作

## 课前回顾 (1分钟)

前面7节课我们学了：
- 归约优化（第3-5课）：60倍加速
- 矩阵乘法（第6-7课）：从朴素到高效

**今天的主题**：让GPU更忙！充分利用硬件并发能力。

---

## 今天要解决的问题 (1分钟)

**传统GPU程序的时间线**：
```
CPU: [准备数据]                    [处理结果]
                 ↓                  ↑
GPU:         [H2D传输] [Kernel执行] [D2H传输]
             └────────串行执行────────┘

总时间 = 传输 + 计算 + 传输
```

**问题**：
- 传输时GPU空闲（浪费）
- 计算时传输通道空闲（浪费）
- 能否重叠执行？

---

## 核心概念速讲 (3分钟)

### 1. CUDA Stream（流）

**定义**：
- 独立的操作队列
- 不同stream中的操作可以并发执行
- 同一stream内的操作按顺序执行

**类比**：
```
Stream就像高速公路的车道：
- 单车道（无stream）：所有车排队
- 多车道（多stream）：车辆并行前进
```

**创建和使用**：
```cuda
cudaStream_t stream;
cudaStreamCreate(&stream);  // 创建stream

// 在stream中执行操作
cudaMemcpyAsync(..., stream);
kernel<<<grid, block, 0, stream>>>();
cudaMemcpyAsync(..., stream);

cudaStreamDestroy(stream);  // 销毁
```

---

### 2. 异步操作

**同步 vs 异步**：

**同步**（默认）：
```cuda
cudaMemcpy(..., cudaMemcpyHostToDevice);  // CPU等待传输完成
kernel<<<...>>>();  // CPU等待启动完成（但不等执行完）
cudaMemcpy(..., cudaMemcpyDeviceToHost);  // CPU等待传输完成
```

**异步**：
```cuda
cudaMemcpyAsync(..., stream);  // CPU立即返回，不等待
kernel<<<..., stream>>>();     // CPU立即返回
cudaMemcpyAsync(..., stream);  // CPU立即返回
// 后台并发执行
```

---

### 3. Pinned Memory（固定内存）

**问题**：为什么需要特殊内存？

**普通内存**（Pageable）：
- 操作系统可以换出到硬盘
- GPU不能直接访问
- 传输时需要先复制到临时缓冲区

**Pinned Memory**：
- 锁定在物理内存，不会被换出
- GPU可以直接DMA访问
- 传输速度快2-3倍
- **异步拷贝必须用Pinned Memory**

**使用**：
```cuda
float *h_data;
cudaMallocHost(&h_data, size);  // 分配pinned memory
// 使用...
cudaFreeHost(h_data);  // 释放
```

**注意**：不要过度使用（消耗系统资源）

---

### 4. 计算与传输重叠

**单Stream**（串行）：
```
Timeline:
Stream 0: [H2D_0][Kernel_0][D2H_0][H2D_1][Kernel_1][D2H_1]
          └──────────────────────────────────────────┘
          总时间 = 6个时间单位
```

**多Stream**（并发）：
```
Timeline:
Stream 0: [H2D_0][Kernel_0][D2H_0]
Stream 1:    [H2D_1][Kernel_1][D2H_1]
Stream 2:       [H2D_2][Kernel_2][D2H_2]
          └────────────┘
          总时间 = 3个时间单位（理想情况）
```

**重叠原理**：
- PCIe传输引擎 + GPU计算单元 = 独立硬件
- Stream 0在传输时，Stream 1可以计算
- 总时间 ≈ max(传输时间, 计算时间)

---

## 今天的代码结构

```cuda
// 创建多个streams
cudaStream_t streams[4];
for (int i = 0; i < 4; i++) {
    cudaStreamCreate(&streams[i]);
}

// 将数据分成4块，每块用一个stream处理
int chunkSize = N / 4;

for (int i = 0; i < 4; i++) {
    int offset = i * chunkSize;

    // Stream i 的操作（异步）
    cudaMemcpyAsync(d_data + offset, h_data + offset,
                    chunkSize * sizeof(float),
                    cudaMemcpyHostToDevice,
                    streams[i]);

    kernel<<<blocks, threads, 0, streams[i]>>>(
        d_data + offset, chunkSize);

    cudaMemcpyAsync(h_result + offset, d_result + offset,
                    chunkSize * sizeof(float),
                    cudaMemcpyDeviceToHost,
                    streams[i]);
}

// 等待所有streams完成
cudaDeviceSynchronize();

// 销毁streams
for (int i = 0; i < 4; i++) {
    cudaStreamDestroy(streams[i]);
}
```

---

## 性能分析要点

### 使用Nsight Systems查看时间线

**编译运行**：
```bash
nvcc -o lesson10 1001-streams-async.cu
nsys profile -o report ./lesson10
nsys-ui report.nsys-rep  # 打开GUI查看
```

**查看重点**：
1. **Kernel执行**：是否真的并发？
2. **内存传输**：H2D和D2H是否重叠？
3. **空闲gap**：是否有可优化空间？
4. **Stream依赖**：是否有意外的同步？

**期望看到的图**：
```
Stream 0: [H2D]──[Kernel]──[D2H]
Stream 1:   [H2D]──[Kernel]──[D2H]
Stream 2:     [H2D]──[Kernel]──[D2H]
Stream 3:       [H2D]──[Kernel]──[D2H]
          └───────────┘ 重叠！
```

---

## 常见陷阱

### 1. Default Stream会阻塞

```cuda
kernel1<<<grid, block>>>();           // Default stream (NULL)
kernel2<<<grid, block, 0, stream1>>>(); // 会等kernel1完成！
```

**解决**：总是显式指定stream

### 2. 数据依赖导致串行

```cuda
// 错误：Stream 1依赖Stream 0的数据
cudaMemcpyAsync(d_a, h_a, size, ..., stream0);
kernel<<<..., stream1>>>(d_a, ...);  // 读d_a，必须等stream0完成
```

**解决**：确保每个stream处理独立数据

### 3. Pinned Memory不足

```cuda
cudaMallocHost(&h_data, 10GB);  // 可能失败！
```

**解决**：适度使用，不要超过物理内存的10-20%

---

## 性能预期

| 实现 | 总时间 | 加速比 |
|------|--------|--------|
| 同步版 | H2D + Kernel + D2H | 1x |
| 4-Stream异步 | max(H2D, Kernel, D2H) | 1.5-2.5x |

**实际加速取决于**：
- 传输时间 vs 计算时间比例
- PCIe带宽 vs GPU算力
- 数据量和kernel复杂度

---

## 本节课目标

学完后你应该能：
- ✅ 创建和使用CUDA Streams
- ✅ 理解异步执行模型
- ✅ 使用Pinned Memory加速传输
- ✅ 实现计算与传输重叠
- ✅ 用Nsight Systems分析性能

---

## 接下来：20分钟 Live Coding

重点：
1. 对比同步vs异步版本
2. 创建多个streams
3. 分块处理数据
4. Nsight Systems可视化分析

**这是核心课程的最后一课！** 🎉

---

## 课程总结

**你已经学会了**：
- 第3-5课：归约优化（60x加速）
- 第6-7课：矩阵乘法（1000+ GFLOPS）
- 第10课：异步并发（隐藏延迟）

**下一步建议**：
- 学习cuBLAS/cuDNN库
- 尝试Tensor Cores（FP16）
- 实战项目：深度学习算子

**恭喜完成CUDA核心课程！** 🚀
